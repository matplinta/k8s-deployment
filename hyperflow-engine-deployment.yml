apiVersion: apps/v1
kind: Deployment
metadata:
  name: hyperflow-engine
spec:
  replicas: 1
  selector:
    matchLabels:
      name: hyperflow-engine
      component: hyperflow-engine
  template:
    metadata:
      labels:
        name: hyperflow-engine
        component: hyperflow-engine
    spec:
      containers:
      - name: hyperflow
        image: matplinta/hyperflow:node12
        imagePullPolicy: Always
        lifecycle:
          preStop:
            exec:
              command: 
                - "/bin/sh"
                - "-c"
                - >
                  echo 1 > /work_dir/postprocStart
        env:
        - name: REDIS_URL
          # Change that value to reflect your and namespace and cluster FQDN
          value: redis://redis.default.svc.cluster.local:6379
        - name: HF_VAR_function
          # The source of this function can be found here
          # https://github.com/hyperflow-wms/hyperflow/blob/master/functions/k8sCommand.js
          value: "k8sCommand"
        - name: HF_VAR_JOB_TEMPLATE_PATH
          value: "/opt/hyperflow/job-template.yaml"
        - name: HF_VAR_WORKER_CONTAINER
          # value: "hyperflowwms/soykb-workflow-worker:v1.0.10-1-g95b7caf"
          value: "hyperflowwms/montage-workflow-worker:v1.0.9-1-gd61c86c"
        - name: HF_VAR_WORK_DIR
          value: "/work_dir"
        - name: HF_VAR_DEBUG
          value: "0"
        - name: HF_VAR_BACKOFF_LIMIT
          value: "0"
        - name: HF_VAR_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        command:
          - "/bin/sh"
          - "-c"
          - >
            echo "Hyperflow environmental variables:" ;
            env | grep "HF_" ;
            while ! [ -f /work_dir/workflow.json ]; do echo "Waiting for workflow.json to be mounted..." ; done ;
            echo "Workflow data mounted: " ; ls -la /work_dir ;
            if [ $HF_VAR_DEBUG -eq 0 ] ; then
              cd /work_dir/ ;
              echo "Running workflow:" ;
              hflow run workflow.json ;
              hflow-info /work_dir/workflow.json --print -f /work_dir | tee /work_dir/file_sizes.log
              echo "Workflow finished." ;
            fi ;
        volumeMounts:
           - name: workflow-data
             mountPath: "/work_dir:shared"
           - name: config-map
             mountPath: /opt/hyperflow/job-template.yaml
             subPath: job-template.yaml
             readOnly: true
      volumes:
      - name: config-map
        configMap:
          name: hyperflow-config
      - name: workflow-data
        persistentVolumeClaim:
          claimName: nfs

